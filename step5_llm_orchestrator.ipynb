{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tPAZNOUQXmN"
      },
      "source": [
        "# Step 5: LLM Orchestrator\n",
        "\n",
        "This notebook implements the LLM Orchestrator for the accounting automation pipeline.\n",
        "\n",
        "**Input:**\n",
        "- Structured JSON from data extraction (step 2)\n",
        "- Embedding vectors (.npy or list of floats) from step 3\n",
        "- Reconciled similarity matches and deduplicated entries from step 4\n",
        "\n",
        "**Output:**\n",
        "- Reasoning trace\n",
        "- Validation logs\n",
        "- Explanations\n",
        "\n",
        "**Model:** Gemini 2.5 Pro via LangChain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpdo-Tg0QXmQ",
        "outputId": "64b7c544-16a5-40b3-b883-72ae09c755e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q langchain langchain-google-genai google-generativeai fastapi uvicorn pydantic numpy pandas python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community\n",
        "7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5empXLaRECZ",
        "outputId": "c86024ef-5418-4bfc-f373-1b8489fb8732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m471.2/471.2 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.0.10 requires langchain-core<0.4.0,>=0.3.37, but you have langchain-core 1.0.4 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.4 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmrZgfMtQXmR"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from dataclasses import dataclass, asdict\n",
        "from enum import Enum\n",
        "\n",
        "# LangChain imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "# Pydantic for validation\n",
        "from pydantic import BaseModel, Field, validator\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq5duczbQXmR"
      },
      "source": [
        "## Configuration\n",
        "\n",
        "Set your Google API key here. You can get it from [Google AI Studio](https://makersuite.google.com/app/apikey)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KkoiNZFQXmS",
        "outputId": "07969efb-aceb-4b05-d0f1-a5d5b89dc8ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized LLM with model: gemini-2.5-pro\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "from google.colab import userdata\n",
        "\n",
        "# ğŸ”‘ Replace with your actual API key\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "# Model configuration\n",
        "# Try Gemini 2.5 Pro first. If not available, fallback to: \"gemini-1.5-pro\" or \"gemini-2.0-flash-exp\"\n",
        "MODEL_NAME = \"gemini-2.5-pro\"  # Gemini 2.5 Pro model\n",
        "TEMPERATURE = 0.1  # Low temperature for consistent, factual outputs\n",
        "MAX_TOKENS = 4096\n",
        "\n",
        "# Initialize the LLM\n",
        "try:\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=MODEL_NAME,\n",
        "        google_api_key=GOOGLE_API_KEY,\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "    print(f\"Initialized LLM with model: {MODEL_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing {MODEL_NAME}: {e}\")\n",
        "    print(\"Falling back to gemini-1.5-pro...\")\n",
        "    MODEL_NAME = \"gemini-1.5-pro\"\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=MODEL_NAME,\n",
        "        google_api_key=GOOGLE_API_KEY,\n",
        "        temperature=TEMPERATURE,\n",
        "        max_tokens=MAX_TOKENS,\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "    print(f\"Initialized LLM with fallback model: {MODEL_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw46FeEXQXmS"
      },
      "source": [
        "## Data Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4XNxaLoQXmS"
      },
      "outputs": [],
      "source": [
        "# Data models for structured input/output\n",
        "class ValidationStatus(str, Enum):\n",
        "    VALID = \"valid\"\n",
        "    INVALID = \"invalid\"\n",
        "    WARNING = \"warning\"\n",
        "    NEEDS_REVIEW = \"needs_review\"\n",
        "\n",
        "class ExtractedRecord(BaseModel):\n",
        "    \"\"\"Structured JSON record from step 2\"\"\"\n",
        "    vendor: Optional[str] = None\n",
        "    date: Optional[str] = None\n",
        "    amount: Optional[float] = None\n",
        "    tax: Optional[float] = None\n",
        "    total: Optional[float] = None\n",
        "    invoice_number: Optional[str] = None\n",
        "    description: Optional[str] = None\n",
        "    category: Optional[str] = None\n",
        "    payment_method: Optional[str] = None\n",
        "    raw_text: Optional[str] = None\n",
        "\n",
        "class ReconciliationMatch(BaseModel):\n",
        "    \"\"\"Reconciled similarity match from step 4\"\"\"\n",
        "    record_id: str\n",
        "    matched_record_ids: List[str]\n",
        "    similarity_scores: List[float]\n",
        "    is_duplicate: bool\n",
        "    confidence: float\n",
        "\n",
        "class ValidationResult(BaseModel):\n",
        "    \"\"\"Validation result for a record\"\"\"\n",
        "    record_id: str\n",
        "    status: ValidationStatus\n",
        "    issues: List[str]\n",
        "    confidence: float\n",
        "    reasoning: str\n",
        "\n",
        "class ReasoningTrace(BaseModel):\n",
        "    \"\"\"Reasoning trace for a record\"\"\"\n",
        "    record_id: str\n",
        "    timestamp: str\n",
        "    steps: List[Dict[str, Any]]\n",
        "    final_conclusion: str\n",
        "    confidence_score: float\n",
        "\n",
        "class OrchestrationOutput(BaseModel):\n",
        "    \"\"\"Complete orchestration output\"\"\"\n",
        "    record_id: str\n",
        "    validation_result: ValidationResult\n",
        "    reasoning_trace: ReasoningTrace\n",
        "    explanation: str\n",
        "    recommendations: List[str]\n",
        "    metadata: Dict[str, Any]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3GXAFgEQXmS"
      },
      "source": [
        "## LLM Orchestrator Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWGrDB3MQXmT"
      },
      "outputs": [],
      "source": [
        "class LLMOrchestrator:\n",
        "    \"\"\"\n",
        "    LLM Orchestrator for accounting automation pipeline.\n",
        "    Handles validation, reasoning, and explanation generation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, llm: ChatGoogleGenerativeAI):\n",
        "        self.llm = llm\n",
        "        self.validation_logs = []\n",
        "        self.reasoning_traces = []\n",
        "\n",
        "        # Define prompts\n",
        "        self.validation_prompt = self._create_validation_prompt()\n",
        "        self.reasoning_prompt = self._create_reasoning_prompt()\n",
        "        self.explanation_prompt = self._create_explanation_prompt()\n",
        "\n",
        "    def _create_validation_prompt(self) -> ChatPromptTemplate:\n",
        "        \"\"\"Create prompt for validation\"\"\"\n",
        "        template = \"\"\"You are an expert accounting validation system. Your task is to validate extracted financial records.\n",
        "\n",
        "Given a structured JSON record, analyze it for:\n",
        "1. Completeness: Are all critical fields present?\n",
        "2. Consistency: Do the numbers add up correctly (amount + tax = total)?\n",
        "3. Format: Are dates, amounts, and other fields in correct format?\n",
        "4. Reasonableness: Are the values within expected ranges?\n",
        "5. Business logic: Does the record make business sense?\n",
        "\n",
        "Extracted Record:\n",
        "{record_json}\n",
        "\n",
        "Reconciliation Information:\n",
        "{reconciliation_info}\n",
        "\n",
        "Provide your validation in the following JSON format:\n",
        "{{\n",
        "    \"status\": \"valid|invalid|warning|needs_review\",\n",
        "    \"issues\": [\"list of issues found\"],\n",
        "    \"confidence\": 0.0-1.0,\n",
        "    \"reasoning\": \"detailed explanation of validation\"\n",
        "}}\n",
        "\n",
        "Be thorough and precise. Flag any potential issues.\"\"\"\n",
        "\n",
        "        return ChatPromptTemplate.from_messages([\n",
        "            SystemMessage(content=\"You are an expert accounting validation system.\"),\n",
        "            HumanMessage(content=template)\n",
        "        ])\n",
        "\n",
        "    def _create_reasoning_prompt(self) -> ChatPromptTemplate:\n",
        "        \"\"\"Create prompt for reasoning trace\"\"\"\n",
        "        template = \"\"\"You are an AI reasoning system for accounting records. Generate a step-by-step reasoning trace.\n",
        "\n",
        "Record:\n",
        "{record_json}\n",
        "\n",
        "Reconciliation Info:\n",
        "{reconciliation_info}\n",
        "\n",
        "Validation Result:\n",
        "{validation_result}\n",
        "\n",
        "Generate a detailed reasoning trace showing:\n",
        "1. Initial analysis of the record\n",
        "2. Field-by-field examination\n",
        "3. Cross-field consistency checks\n",
        "4. Reconciliation analysis (if applicable)\n",
        "5. Final conclusion\n",
        "\n",
        "Format as JSON:\n",
        "{{\n",
        "    \"steps\": [\n",
        "        {{\"step\": 1, \"action\": \"analyzed field X\", \"observation\": \"...\", \"conclusion\": \"...\"}},\n",
        "        ...\n",
        "    ],\n",
        "    \"final_conclusion\": \"summary of reasoning\",\n",
        "    \"confidence_score\": 0.0-1.0\n",
        "}}\"\"\"\n",
        "\n",
        "        return ChatPromptTemplate.from_messages([\n",
        "            SystemMessage(content=\"You are an AI reasoning system for accounting records.\"),\n",
        "            HumanMessage(content=template)\n",
        "        ])\n",
        "\n",
        "    def _create_explanation_prompt(self) -> ChatPromptTemplate:\n",
        "        \"\"\"Create prompt for explanation generation\"\"\"\n",
        "        template = \"\"\"Generate a clear, human-readable explanation of the validation and reasoning process.\n",
        "\n",
        "Record:\n",
        "{record_json}\n",
        "\n",
        "Validation Result:\n",
        "{validation_result}\n",
        "\n",
        "Reasoning Trace:\n",
        "{reasoning_trace}\n",
        "\n",
        "Provide:\n",
        "1. A summary of what was analyzed\n",
        "2. Key findings\n",
        "3. Any issues or concerns\n",
        "4. Recommendations for next steps\n",
        "\n",
        "Write in clear, professional language suitable for accounting professionals.\"\"\"\n",
        "\n",
        "        return ChatPromptTemplate.from_messages([\n",
        "            SystemMessage(content=\"You are an expert accounting analyst explaining validation results.\"),\n",
        "            HumanMessage(content=template)\n",
        "        ])\n",
        "\n",
        "    def validate_record(\n",
        "        self,\n",
        "        record: Dict[str, Any],\n",
        "        reconciliation_info: Optional[Dict[str, Any]] = None\n",
        "    ) -> ValidationResult:\n",
        "        \"\"\"Validate a single record using LLM\"\"\"\n",
        "        try:\n",
        "            # Prepare inputs\n",
        "            record_json = json.dumps(record, indent=2)\n",
        "            recon_json = json.dumps(reconciliation_info, indent=2) if reconciliation_info else \"No reconciliation data\"\n",
        "\n",
        "            # Create prompt\n",
        "            messages = self.validation_prompt.format_messages(\n",
        "                record_json=record_json,\n",
        "                reconciliation_info=recon_json\n",
        "            )\n",
        "\n",
        "            # Call LLM\n",
        "            response = self.llm.invoke(messages)\n",
        "            response_text = response.content\n",
        "\n",
        "            # Parse JSON from response (handle markdown code blocks)\n",
        "            if \"```json\" in response_text:\n",
        "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in response_text:\n",
        "                response_text = response_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            validation_data = json.loads(response_text)\n",
        "\n",
        "            # Create validation result\n",
        "            result = ValidationResult(\n",
        "                record_id=record.get(\"record_id\", \"unknown\"),\n",
        "                status=ValidationStatus(validation_data.get(\"status\", \"needs_review\")),\n",
        "                issues=validation_data.get(\"issues\", []),\n",
        "                confidence=validation_data.get(\"confidence\", 0.5),\n",
        "                reasoning=validation_data.get(\"reasoning\", \"\")\n",
        "            )\n",
        "\n",
        "            # Log validation\n",
        "            self.validation_logs.append({\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"record_id\": result.record_id,\n",
        "                \"status\": result.status.value,\n",
        "                \"issues\": result.issues\n",
        "            })\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Validation error: {e}\")\n",
        "            return ValidationResult(\n",
        "                record_id=record.get(\"record_id\", \"unknown\"),\n",
        "                status=ValidationStatus.NEEDS_REVIEW,\n",
        "                issues=[f\"Validation error: {str(e)}\"],\n",
        "                confidence=0.0,\n",
        "                reasoning=f\"Error during validation: {str(e)}\"\n",
        "            )\n",
        "\n",
        "    def generate_reasoning_trace(\n",
        "        self,\n",
        "        record: Dict[str, Any],\n",
        "        validation_result: ValidationResult,\n",
        "        reconciliation_info: Optional[Dict[str, Any]] = None\n",
        "    ) -> ReasoningTrace:\n",
        "        \"\"\"Generate reasoning trace for a record\"\"\"\n",
        "        try:\n",
        "            record_json = json.dumps(record, indent=2)\n",
        "            recon_json = json.dumps(reconciliation_info, indent=2) if reconciliation_info else \"No reconciliation data\"\n",
        "            validation_json = json.dumps(asdict(validation_result), indent=2)\n",
        "\n",
        "            messages = self.reasoning_prompt.format_messages(\n",
        "                record_json=record_json,\n",
        "                reconciliation_info=recon_json,\n",
        "                validation_result=validation_json\n",
        "            )\n",
        "\n",
        "            response = self.llm.invoke(messages)\n",
        "            response_text = response.content\n",
        "\n",
        "            # Parse JSON from response\n",
        "            if \"```json\" in response_text:\n",
        "                response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "            elif \"```\" in response_text:\n",
        "                response_text = response_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "            trace_data = json.loads(response_text)\n",
        "\n",
        "            trace = ReasoningTrace(\n",
        "                record_id=record.get(\"record_id\", \"unknown\"),\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                steps=trace_data.get(\"steps\", []),\n",
        "                final_conclusion=trace_data.get(\"final_conclusion\", \"\"),\n",
        "                confidence_score=trace_data.get(\"confidence_score\", 0.5)\n",
        "            )\n",
        "\n",
        "            self.reasoning_traces.append(asdict(trace))\n",
        "\n",
        "            return trace\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Reasoning trace error: {e}\")\n",
        "            return ReasoningTrace(\n",
        "                record_id=record.get(\"record_id\", \"unknown\"),\n",
        "                timestamp=datetime.now().isoformat(),\n",
        "                steps=[{\"step\": 1, \"action\": \"error\", \"observation\": str(e), \"conclusion\": \"Error occurred\"}],\n",
        "                final_conclusion=f\"Error generating reasoning trace: {str(e)}\",\n",
        "                confidence_score=0.0\n",
        "            )\n",
        "\n",
        "    def generate_explanation(\n",
        "        self,\n",
        "        record: Dict[str, Any],\n",
        "        validation_result: ValidationResult,\n",
        "        reasoning_trace: ReasoningTrace\n",
        "    ) -> str:\n",
        "        \"\"\"Generate human-readable explanation\"\"\"\n",
        "        try:\n",
        "            record_json = json.dumps(record, indent=2)\n",
        "            validation_json = json.dumps(asdict(validation_result), indent=2)\n",
        "            trace_json = json.dumps(asdict(reasoning_trace), indent=2)\n",
        "\n",
        "            messages = self.explanation_prompt.format_messages(\n",
        "                record_json=record_json,\n",
        "                validation_result=validation_json,\n",
        "                reasoning_trace=trace_json\n",
        "            )\n",
        "\n",
        "            response = self.llm.invoke(messages)\n",
        "            return response.content\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Explanation generation error: {e}\")\n",
        "            return f\"Error generating explanation: {str(e)}\"\n",
        "\n",
        "    def orchestrate(\n",
        "        self,\n",
        "        structured_json: Dict[str, Any],\n",
        "        embedding_vector: Optional[np.ndarray] = None,\n",
        "        reconciliation_data: Optional[Dict[str, Any]] = None\n",
        "    ) -> OrchestrationOutput:\n",
        "        \"\"\"\n",
        "        Main orchestration method that combines all steps.\n",
        "\n",
        "        Args:\n",
        "            structured_json: Extracted JSON record from step 2\n",
        "            embedding_vector: Embedding vector from step 3 (optional, for metadata)\n",
        "            reconciliation_data: Reconciliation matches from step 4 (optional)\n",
        "\n",
        "        Returns:\n",
        "            Complete orchestration output with validation, reasoning, and explanation\n",
        "        \"\"\"\n",
        "        record_id = structured_json.get(\"record_id\", f\"record_{datetime.now().timestamp()}\")\n",
        "        structured_json[\"record_id\"] = record_id\n",
        "\n",
        "        # Step 1: Validate\n",
        "        logger.info(f\"Validating record {record_id}...\")\n",
        "        validation_result = self.validate_record(structured_json, reconciliation_data)\n",
        "\n",
        "        # Step 2: Generate reasoning trace\n",
        "        logger.info(f\"Generating reasoning trace for record {record_id}...\")\n",
        "        reasoning_trace = self.generate_reasoning_trace(\n",
        "            structured_json,\n",
        "            validation_result,\n",
        "            reconciliation_data\n",
        "        )\n",
        "\n",
        "        # Step 3: Generate explanation\n",
        "        logger.info(f\"Generating explanation for record {record_id}...\")\n",
        "        explanation = self.generate_explanation(structured_json, validation_result, reasoning_trace)\n",
        "\n",
        "        # Step 4: Generate recommendations\n",
        "        recommendations = self._generate_recommendations(validation_result, reasoning_trace)\n",
        "\n",
        "        # Step 5: Prepare metadata\n",
        "        # Handle embedding shape for both numpy arrays and lists\n",
        "        embedding_shape = None\n",
        "        if embedding_vector is not None:\n",
        "            if isinstance(embedding_vector, np.ndarray):\n",
        "                embedding_shape = list(embedding_vector.shape)\n",
        "            elif isinstance(embedding_vector, list):\n",
        "                embedding_shape = [len(embedding_vector)]\n",
        "            else:\n",
        "                embedding_shape = \"unknown\"\n",
        "\n",
        "        metadata = {\n",
        "            \"embedding_shape\": embedding_shape,\n",
        "            \"has_reconciliation\": reconciliation_data is not None,\n",
        "            \"processing_timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        return OrchestrationOutput(\n",
        "            record_id=record_id,\n",
        "            validation_result=validation_result,\n",
        "            reasoning_trace=reasoning_trace,\n",
        "            explanation=explanation,\n",
        "            recommendations=recommendations,\n",
        "            metadata=metadata\n",
        "        )\n",
        "\n",
        "    def _generate_recommendations(\n",
        "        self,\n",
        "        validation_result: ValidationResult,\n",
        "        reasoning_trace: ReasoningTrace\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Generate recommendations based on validation and reasoning\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        if validation_result.status == ValidationStatus.INVALID:\n",
        "            recommendations.append(\"Record requires manual review before processing\")\n",
        "            recommendations.append(\"Fix identified issues before ledger entry\")\n",
        "\n",
        "        if validation_result.status == ValidationStatus.WARNING:\n",
        "            recommendations.append(\"Review flagged issues before finalizing\")\n",
        "\n",
        "        if validation_result.confidence < 0.7:\n",
        "            recommendations.append(\"Low confidence score - consider manual verification\")\n",
        "\n",
        "        if validation_result.issues:\n",
        "            recommendations.append(f\"Address {len(validation_result.issues)} identified issue(s)\")\n",
        "\n",
        "        if not recommendations:\n",
        "            recommendations.append(\"Record appears valid and ready for ledger entry\")\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def get_validation_logs(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Get all validation logs\"\"\"\n",
        "        return self.validation_logs\n",
        "\n",
        "    def get_reasoning_traces(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Get all reasoning traces\"\"\"\n",
        "        return self.reasoning_traces\n",
        "\n",
        "    def export_logs(self, filepath: str):\n",
        "        \"\"\"Export all logs to JSON file\"\"\"\n",
        "        export_data = {\n",
        "            \"validation_logs\": self.validation_logs,\n",
        "            \"reasoning_traces\": self.reasoning_traces,\n",
        "            \"export_timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        with open(filepath, 'w') as f:\n",
        "            json.dump(export_data, f, indent=2)\n",
        "        logger.info(f\"Logs exported to {filepath}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGerfn3QQXmU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjlYJmoGQXmU",
        "outputId": "d2d8e787-4218-499f-de68-514f744b9922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Orchestrator initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initialize the orchestrator\n",
        "orchestrator = LLMOrchestrator(llm)\n",
        "print(\"LLM Orchestrator initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH8pZnDPQXmU"
      },
      "source": [
        "## Example Usage\n",
        "\n",
        "### Example 1: Process a single record with all inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPBE5VunQXmU",
        "outputId": "e70c9a28-5f4c-4d67-84e1-be7863afbe01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing record through LLM Orchestrator...\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "ERROR:__main__:Reasoning trace error: asdict() should be called on dataclass instances\n",
            "ERROR:__main__:Explanation generation error: asdict() should be called on dataclass instances\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ORCHESTRATION OUTPUT\n",
            "================================================================================\n",
            "\n",
            "Record ID: record_1762686473.403411\n",
            "\n",
            "Validation Status: invalid\n",
            "Confidence: 1.00\n",
            "Issues: [\"Format Error: 'invoice_date' (2023-13-01) is an invalid date. The month '13' does not exist.\", \"Format Error: 'due_date' (2023-02-30) is an invalid date. February does not have 30 days.\", 'Consistency Error: The sum of amount (1500.00) and tax (120.00) is 1620.00, which does not match the provided total (1600.00).', 'Reconciliation Mismatch: The invoice total (1600.00) does not match the Purchase Order total (1620.00).']\n",
            "\n",
            "Reasoning: The record is invalid due to multiple critical errors in format, consistency, and reconciliation.\n",
            "\n",
            "1.  **Completeness:** All critical fields (invoice_id, vendor_name, dates, amounts) are present. No issues found.\n",
            "\n",
            "2.  **Format:** The record contains two invalid dates. The 'invoice_date' of '2023-13-01' is impossible as there is no 13th month. The 'due_date' of '2023-02-30' is also impossible as February 2023 only has 28 days. All numeric and string formats are otherwise correct.\n",
            "\n",
            "3.  **Consistency:** There is a mathematical inconsistency. The 'amount' (1500.00) plus the 'tax' (120.00) equals 1620.00. This calculated sum does not match the 'total' field, which is 1600.00. The sum of line item totals (1500.00) correctly matches the base 'amount'.\n",
            "\n",
            "4.  **Reasonableness:** The calculated tax rate (tax/amount = 120.00/1500.00 = 8%) is within the expected range of 5% to 10% as specified in the reconciliation information. The values themselves are not unreasonable.\n",
            "\n",
            "5.  **Business Logic:** The vendor 'Innovate Tech Inc.' is present in the vendor master list. However, there is a mismatch between the invoice total (1600.00) and the corresponding Purchase Order total (1620.00). It is highly probable that the 'total' field in the extracted record is incorrect and should be 1620.00, which would resolve both the internal consistency and the PO reconciliation issues.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "REASONING TRACE\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Step 1:\n",
            "  Action: error\n",
            "  Observation: asdict() should be called on dataclass instances\n",
            "  Conclusion: Error occurred\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "EXPLANATION\n",
            "--------------------------------------------------------------------------------\n",
            "Error generating explanation: asdict() should be called on dataclass instances\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "RECOMMENDATIONS\n",
            "--------------------------------------------------------------------------------\n",
            "1. Record requires manual review before processing\n",
            "2. Fix identified issues before ledger entry\n",
            "3. Address 4 identified issue(s)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "METADATA\n",
            "--------------------------------------------------------------------------------\n",
            "{\n",
            "  \"embedding_shape\": [\n",
            "    768\n",
            "  ],\n",
            "  \"has_reconciliation\": true,\n",
            "  \"processing_timestamp\": \"2025-11-09T11:08:20.812159\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Example structured JSON from step 2\n",
        "example_record = {\n",
        "    \"vendor\": \"Amazon Web Services\",\n",
        "    \"date\": \"2024-01-15\",\n",
        "    \"amount\": 1250.00,\n",
        "    \"tax\": 112.50,\n",
        "    \"total\": 1362.50,\n",
        "    \"invoice_number\": \"INV-2024-001234\",\n",
        "    \"description\": \"Cloud hosting services - January 2024\",\n",
        "    \"category\": \"IT Services\",\n",
        "    \"payment_method\": \"Credit Card\",\n",
        "    \"raw_text\": \"Invoice from AWS for cloud services...\"\n",
        "}\n",
        "\n",
        "# Example embedding vector from step 3 (dummy data for demonstration)\n",
        "example_embedding = np.random.rand(768)  # Typical embedding dimension\n",
        "\n",
        "# Example reconciliation data from step 4\n",
        "example_reconciliation = {\n",
        "    \"matched_record_ids\": [\"record_001\", \"record_002\"],\n",
        "    \"similarity_scores\": [0.95, 0.87],\n",
        "    \"is_duplicate\": False,\n",
        "    \"confidence\": 0.92\n",
        "}\n",
        "\n",
        "# Process the record\n",
        "print(\"Processing record through LLM Orchestrator...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "output = orchestrator.orchestrate(\n",
        "    structured_json=example_record,\n",
        "    embedding_vector=example_embedding,\n",
        "    reconciliation_data=example_reconciliation\n",
        ")\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ORCHESTRATION OUTPUT\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nRecord ID: {output.record_id}\")\n",
        "print(f\"\\nValidation Status: {output.validation_result.status.value}\")\n",
        "print(f\"Confidence: {output.validation_result.confidence:.2f}\")\n",
        "print(f\"Issues: {output.validation_result.issues}\")\n",
        "print(f\"\\nReasoning: {output.validation_result.reasoning}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"REASONING TRACE\")\n",
        "print(\"-\" * 80)\n",
        "for i, step in enumerate(output.reasoning_trace.steps, 1):\n",
        "    print(f\"\\nStep {i}:\")\n",
        "    print(f\"  Action: {step.get('action', 'N/A')}\")\n",
        "    print(f\"  Observation: {step.get('observation', 'N/A')}\")\n",
        "    print(f\"  Conclusion: {step.get('conclusion', 'N/A')}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"EXPLANATION\")\n",
        "print(\"-\" * 80)\n",
        "print(output.explanation)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"RECOMMENDATIONS\")\n",
        "print(\"-\" * 80)\n",
        "for i, rec in enumerate(output.recommendations, 1):\n",
        "    print(f\"{i}. {rec}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"METADATA\")\n",
        "print(\"-\" * 80)\n",
        "print(json.dumps(output.metadata, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# ğŸ”‘ Replace with your actual API key\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")  # Set your API key here or use environment variable\n",
        "\n",
        "# Configure Gemini client\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# âœ… STEP 3: Initialize and test connection\n",
        "try:\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "    response = model.generate_content(\"Hello Gemini! Can you confirm the connection is working?\")\n",
        "    print(\"âœ… Gemini Connection Successful!\\n\")\n",
        "    print(\"Response:\", response.text)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"âŒ Connection failed.\\n\")\n",
        "    print(\"Error:\", str(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "VDouqnPtSMKG",
        "outputId": "05f478c3-2584-468a-b002-d342829020f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini Connection Successful!\n",
            "\n",
            "Response: Hello! Yes, I'm here and ready to chat. How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmzVDjjTQXmU"
      },
      "source": [
        "### Example 2: Process multiple records in batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi4Wsgg8QXmU",
        "outputId": "16662bb0-a2ed-4442-ca3c-19ad14b400e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch of records...\n",
            "================================================================================\n",
            "\n",
            "Processing record 1/3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "ERROR:__main__:Reasoning trace error: asdict() should be called on dataclass instances\n",
            "ERROR:__main__:Explanation generation error: asdict() should be called on dataclass instances\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Status: invalid\n",
            "  Confidence: 0.10\n",
            "\n",
            "Processing record 2/3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Reasoning trace error: asdict() should be called on dataclass instances\n",
            "ERROR:__main__:Explanation generation error: asdict() should be called on dataclass instances\n",
            "/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Status: invalid\n",
            "  Confidence: 0.98\n",
            "\n",
            "Processing record 3/3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Reasoning trace error: asdict() should be called on dataclass instances\n",
            "ERROR:__main__:Explanation generation error: asdict() should be called on dataclass instances\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Status: invalid\n",
            "  Confidence: 0.30\n",
            "\n",
            "================================================================================\n",
            "BATCH PROCESSING SUMMARY\n",
            "================================================================================\n",
            "Total records processed: 3\n",
            "Valid records: 0\n",
            "Records needing review: 0\n",
            "Invalid records: 3\n",
            "Average confidence: 0.46\n"
          ]
        }
      ],
      "source": [
        "# Example batch of records\n",
        "batch_records = [\n",
        "    {\n",
        "        \"vendor\": \"Office Supplies Co\",\n",
        "        \"date\": \"2024-01-20\",\n",
        "        \"amount\": 450.00,\n",
        "        \"tax\": 40.50,\n",
        "        \"total\": 490.50,\n",
        "        \"invoice_number\": \"OS-2024-0056\",\n",
        "        \"description\": \"Office supplies and stationery\",\n",
        "        \"category\": \"Office Expenses\"\n",
        "    },\n",
        "    {\n",
        "        \"vendor\": \"Tech Solutions Inc\",\n",
        "        \"date\": \"2024-01-22\",\n",
        "        \"amount\": 5000.00,\n",
        "        \"tax\": 500.00,\n",
        "        \"total\": 5500.00,\n",
        "        \"invoice_number\": \"TS-2024-0123\",\n",
        "        \"description\": \"Software licenses - Annual\",\n",
        "        \"category\": \"Software\"\n",
        "    },\n",
        "    {\n",
        "        \"vendor\": \"Utilities Corp\",\n",
        "        \"date\": \"2024-01-25\",\n",
        "        \"amount\": 850.00,\n",
        "        \"tax\": 76.50,\n",
        "        \"total\": 926.50,\n",
        "        \"invoice_number\": \"UT-2024-0789\",\n",
        "        \"description\": \"Electricity bill - January\",\n",
        "        \"category\": \"Utilities\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Process batch\n",
        "print(\"Processing batch of records...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "batch_outputs = []\n",
        "for i, record in enumerate(batch_records, 1):\n",
        "    print(f\"\\nProcessing record {i}/{len(batch_records)}...\")\n",
        "    output = orchestrator.orchestrate(\n",
        "        structured_json=record,\n",
        "        embedding_vector=np.random.rand(768),  # Dummy embedding\n",
        "        reconciliation_data=None  # No reconciliation for this example\n",
        "    )\n",
        "    batch_outputs.append(output)\n",
        "    print(f\"  Status: {output.validation_result.status.value}\")\n",
        "    print(f\"  Confidence: {output.validation_result.confidence:.2f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BATCH PROCESSING SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total records processed: {len(batch_outputs)}\")\n",
        "print(f\"Valid records: {sum(1 for o in batch_outputs if o.validation_result.status == ValidationStatus.VALID)}\")\n",
        "print(f\"Records needing review: {sum(1 for o in batch_outputs if o.validation_result.status == ValidationStatus.NEEDS_REVIEW)}\")\n",
        "print(f\"Invalid records: {sum(1 for o in batch_outputs if o.validation_result.status == ValidationStatus.INVALID)}\")\n",
        "print(f\"Average confidence: {np.mean([o.validation_result.confidence for o in batch_outputs]):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVigwm2gQXmU"
      },
      "source": [
        "### Example 3: Load data from previous steps (JSON and .npy files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AmY9gLVQXmV"
      },
      "outputs": [],
      "source": [
        "def load_structured_json(filepath: str) -> Dict[str, Any]:\n",
        "    \"\"\"Load structured JSON from step 2\"\"\"\n",
        "    with open(filepath, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def load_embedding_vector(filepath: str) -> np.ndarray:\n",
        "    \"\"\"Load embedding vector from step 3 (.npy file)\"\"\"\n",
        "    return np.load(filepath)\n",
        "\n",
        "def load_reconciliation_data(filepath: str) -> Dict[str, Any]:\n",
        "    \"\"\"Load reconciliation data from step 4\"\"\"\n",
        "    with open(filepath, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Example usage (uncomment and modify paths as needed):\n",
        "# structured_json = load_structured_json(\"path/to/step2_output.json\")\n",
        "# embedding_vector = load_embedding_vector(\"path/to/step3_output.npy\")\n",
        "# reconciliation_data = load_reconciliation_data(\"path/to/step4_output.json\")\n",
        "#\n",
        "# output = orchestrator.orchestrate(\n",
        "#     structured_json=structured_json,\n",
        "#     embedding_vector=embedding_vector,\n",
        "#     reconciliation_data=reconciliation_data\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYe4oA7KQXmV"
      },
      "source": [
        "## Export Logs and Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOTFBP1NQXmV",
        "outputId": "84e450fb-f5d9-4ed5-e1be-d53d460992b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logs exported to orchestrator_logs.json\n",
            "\n",
            "================================================================================\n",
            "VALIDATION LOGS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "2025-11-09T11:08:20.810565 - Record: record_1762686473.403411\n",
            "  Status: invalid\n",
            "  Issues: 4\n",
            "\n",
            "2025-11-09T11:09:18.832774 - Record: record_1762686519.50255\n",
            "  Status: invalid\n",
            "  Issues: 3\n",
            "\n",
            "2025-11-09T11:09:52.111574 - Record: record_1762686558.835192\n",
            "  Status: invalid\n",
            "  Issues: 3\n",
            "\n",
            "2025-11-09T11:10:23.628149 - Record: record_1762686592.113273\n",
            "  Status: invalid\n",
            "  Issues: 5\n"
          ]
        }
      ],
      "source": [
        "# Export all validation logs and reasoning traces\n",
        "log_filepath = \"orchestrator_logs.json\"\n",
        "orchestrator.export_logs(log_filepath)\n",
        "print(f\"Logs exported to {log_filepath}\")\n",
        "\n",
        "# Display summary of logs\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"VALIDATION LOGS SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "for log in orchestrator.get_validation_logs():\n",
        "    print(f\"\\n{log['timestamp']} - Record: {log['record_id']}\")\n",
        "    print(f\"  Status: {log['status']}\")\n",
        "    print(f\"  Issues: {len(log['issues'])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3wEZcWbQXmV"
      },
      "source": [
        "## Save Orchestration Output\n",
        "\n",
        "Save the complete orchestration output for use in subsequent steps (e.g., ledger engine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGXTjY-7QXmV"
      },
      "outputs": [],
      "source": [
        "def save_orchestration_output(output: OrchestrationOutput, filepath: str):\n",
        "    \"\"\"Save orchestration output to JSON file\"\"\"\n",
        "    output_dict = {\n",
        "        \"record_id\": output.record_id,\n",
        "        \"validation_result\": asdict(output.validation_result),\n",
        "        \"reasoning_trace\": asdict(output.reasoning_trace),\n",
        "        \"explanation\": output.explanation,\n",
        "        \"recommendations\": output.recommendations,\n",
        "        \"metadata\": output.metadata\n",
        "    }\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(output_dict, f, indent=2)\n",
        "    print(f\"Orchestration output saved to {filepath}\")\n",
        "\n",
        "# Example: Save the output from previous examples\n",
        "# save_orchestration_output(output, \"orchestration_output.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEJ3u23DQXmV"
      },
      "source": [
        "## Integration Helper Functions\n",
        "\n",
        "Helper functions to integrate with the full pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IsvcWqtQXmV"
      },
      "outputs": [],
      "source": [
        "def process_pipeline_outputs(\n",
        "    structured_json_path: str,\n",
        "    embedding_vector_path: Optional[str] = None,\n",
        "    reconciliation_data_path: Optional[str] = None\n",
        ") -> OrchestrationOutput:\n",
        "    \"\"\"\n",
        "    Complete pipeline integration function.\n",
        "    Loads outputs from steps 2, 3, and 4 and processes through orchestrator.\n",
        "\n",
        "    Args:\n",
        "        structured_json_path: Path to JSON from step 2\n",
        "        embedding_vector_path: Path to .npy file from step 3 (optional)\n",
        "        reconciliation_data_path: Path to JSON from step 4 (optional)\n",
        "\n",
        "    Returns:\n",
        "        OrchestrationOutput with all validation, reasoning, and explanations\n",
        "    \"\"\"\n",
        "    # Load inputs\n",
        "    structured_json = load_structured_json(structured_json_path)\n",
        "\n",
        "    embedding_vector = None\n",
        "    if embedding_vector_path and os.path.exists(embedding_vector_path):\n",
        "        embedding_vector = load_embedding_vector(embedding_vector_path)\n",
        "\n",
        "    reconciliation_data = None\n",
        "    if reconciliation_data_path and os.path.exists(reconciliation_data_path):\n",
        "        reconciliation_data = load_reconciliation_data(reconciliation_data_path)\n",
        "\n",
        "    # Process through orchestrator\n",
        "    output = orchestrator.orchestrate(\n",
        "        structured_json=structured_json,\n",
        "        embedding_vector=embedding_vector,\n",
        "        reconciliation_data=reconciliation_data\n",
        "    )\n",
        "\n",
        "    return output\n",
        "\n",
        "# Example usage:\n",
        "# output = process_pipeline_outputs(\n",
        "#     structured_json_path=\"step2_output.json\",\n",
        "#     embedding_vector_path=\"step3_output.npy\",\n",
        "#     reconciliation_data_path=\"step4_output.json\"\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKlDA4DJQXmV"
      },
      "source": [
        "## Notes\n",
        "\n",
        "1. **API Key Setup**: Make sure to set your `GOOGLE_API_KEY` in the configuration cell above. Get it from [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
        "2. **Model Selection**: Using `gemini-2.5-pro`. If not available, the code will automatically fallback to `gemini-1.5-pro`\n",
        "3. **Error Handling**: The orchestrator includes comprehensive error handling for API calls and JSON parsing\n",
        "4. **Output Format**: All outputs are structured as Pydantic models for easy integration with step 7 (Ledger Engine)\n",
        "5. **Logging**: All validation logs and reasoning traces are stored and can be exported for audit purposes\n",
        "6. **Input Formats**:\n",
        "   - Structured JSON: Dictionary with fields like vendor, date, amount, tax, total, etc.\n",
        "   - Embedding vectors: NumPy arrays (.npy files) or list of floats\n",
        "   - Reconciliation data: Dictionary with matched_record_ids, similarity_scores, is_duplicate, confidence\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}